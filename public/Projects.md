<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.4/css/all.css" integrity="sha384-DyZ88mC6Up2uqS4h/KRgHuoeGwBcD4Ng9SiP4dIRy0EXTlnuz47vAwmeGwVChigm" crossorigin="anonymous"/>

## Blobodoro

Blobodoro is a Blob fish study companion app that allows you to set Pomodoro timers or stopwatch to tracks your study time and provide statistical information on your study habits.

Built with HTML/CSS/JavaScript (Node.js, Express, MongoDB)

<img id="blob-logo" src="/img/Blobodoro-Logo-V7.png" alt="Blobodoro's Logo" width="200" />


<p class="blob-quote">"~Blob~"</p>
<div class="github-icon">
    <i class="fab fa-github" aria-hidden="true"></i><span> </span><a href="https://github.com/antoniehuang/Blobodoro" style="color: rgb(185, 61, 185);" target="_blank">Blobodoro</a>
</div>

--- 

## Clean from League

Track how long ago since you played League of Legends, this is an app for people who is addicted to League of Legends to mointor their progress and provide positive feedback.

<div class="github-icon">
    <i class="fab fa-github" aria-hidden="true"></i><span> </span><a href="https://github.com/antoniehuang/Clean-from-League" style="color: rgb(185, 61, 185);" target="_blank">Clean From League</a>
</div>

---

## Final Year Project

**Title**: Semi-Supervised Learning with Pseudo-labelling and 
Synthetic Samples

**Abstract**: When training a Convolutional Neural Network for image classification, an important criterion to achieve 
high prediction accuracy is the availability of sufficient training data. Therefore, in a situation where 
training data is scarce, we like to develop methods to achieve a similar result.
In the project, we explored the use of pseudo-labelling and synthetic samples generated from a Generative 
Adversarial Network to increase samples in a limited dataset, under a semi-supervised learning setting. It 
is shown that training a classifier with pseudo-labelled samples achieves a test accuracy of 61.05% which 
is an increase of 3.03% in prediction accuracy when compared to our baseline of 58.02%. Whereas
synthetic samples yield similar test accuracy as the baseline at 57.98%. However, both methods do not 
outperform the best-case performance of the model when trained with sufficient training data at 78.63%